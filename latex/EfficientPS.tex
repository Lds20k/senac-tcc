\subsection{EfficientPS}

EfficientPS é uma solução para a segmentação panóptica proposta no artigo \citeonline{mohan2020efficientps}, o trabalho apresenta uma arquitetura que se inicia com um backbone — parte para identificar características — usando uma FPN de 2 caminhos seguido de dois cabeçotes paralelos um para uma arquitetura de segmentação semântica que é autoria deles e outra de instância com modificações baseadas na topologia Mask R-CNN e finalmente a saída dos dois cabeçotes são combinadas no môdulo de fusão panóptica para gerar a saída final com a imagem de segmentação panóptica, esta arquitetura é ilustrada na \cref{fig:arqEP}.

\begin{figure}[H]
	\caption{Arquitetura geral do EfficientPS}
	\centering % para centralizarmos a figura
	\includegraphics[width=15cm]{figures/arqEP.jpg} % leia abaixo
	\legend{Fonte: \citeonline{mohan2020efficientps}}
	\label{fig:arqEP}
\end{figure}

\subsubsection*{Backbone da rede}

A espinha dorsal — ou backbone — se consiste em uma codificação combinado a uma bifurcação paralela usando FPN. O codificador é essencial para arquiteturas de segmentação e para melhorar a capacidade de representação é necessário aumentar o número de parâmetros e a complexidade, porém nesse artigo os autores chegaram numa solução balanceada nesse quesito. O codificador contém nove blocos (em vermelho), mostrado na \cref{fig:arqEP} e a 2º, 3º, 5º e 9º saídas — da esquerda para diretira — correspondem aos fatores de redução de amostragem x4,x8,x16 e x32 respectivamente. Essas saídas vão conectar com a bifurcação paralela que são de sentidos opostos para gerar mais detecções de características, após isso será feita uma combinação entre camadas de mesma dimensão utilizando camadas de convolução separável em profundidade — divide em etapa espacial e de canal, aplicada a cada canal e cada pixel de saída respactivamente — resultando nas saídas $ P_4 + P_8 + P_{16} + P_{32} $\cite{mohan2020efficientps, redes-neurais-convolucionais-separaveis-em-profundidade}.

\subsubsection*{Cabeçote de Segmentação Semântica}

O cabeçote de segmentação semântica é dividido em três môdulos sendo eles: extrator de características em larga escala — ou Large Scale Feature Extractor (LSFE) — para capturar recursos finos em larga escala de forma eficiente, módulo DPC deve ser capaz de capturar contexto de longo alcance porém em pequena escala e o módulo MC deve ser capaz de mitigar a incompatibilidade entre recursos de grande e pequena escala nas camadas de agregação \cite{mohan2020efficientps}.

As quatro entradas do cabeçote $ P_4 + P_8 + P_{16} + P_{32} $ são separadas, sendo $ P_{16} + P_{32} $ — pequena escala — alimentam dois módulos DPC paralelos e $ P_4 + P_8 $ — larga escala — alimentam dois módulos LSFE paralelos \cite{mohan2020efficientps}.

\subsubsection*{Cabeçote de segmentação de instância}

Este cabeçote é derivada da arquitetura Mask R-CNN e as modificações foram três, sendo elas: trocar a convolução padrão por convolução separável em profundidade — para reduzir o número de parâmetros consumidos pela rede —, camada de normalização em lote foi substituída por iABN Sync — normalização em lotes entre cores de GPU para aumentar o desempenho — e a função ReLU por Leaky ReLU \cite{mohan2020efficientps,redes-neurais-convolucionais-separaveis-em-profundidade, serp-ai}.
	

\subsubsection*{Módulo de fusão panóptica}

O modulo da fusão panóptica é necessário para construir a imagem com segmentação panóptica, nessa parte é fundido os resultados dos dois cabeçotes anteriormente explicados. Esta tarefa não é simples pois é necessário criar uma lógica para obter o melhor resultado diante da sobreposições encontradas. O módulo foi criado no intuito de ser adaptativo e usar as duas entradas de forma equivalente \cite{mohan2020efficientps}.

Resumindo o módulo aplica algumas técnicas para reduzir o número de instâncias baseando-se na métrica logist — valor númerico que pontua confiança —, aplica algumas agregações entre os resultados dos dois cabeçotes, e desenha com fundo preto as instâncias com melhor classificação de confiança, logo depois preenche com a parte de stuff — classes semânticas sem importância — da entrada semântica \cite{mohan2020efficientps}.